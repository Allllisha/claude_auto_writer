"""
AI Creator Alisa Persona Manager
AI Melody Kobo - AIã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼ ã‚¢ãƒªã‚µã®ãƒšãƒ«ã‚½ãƒŠç®¡ç†
"""

import os
import json
from typing import Dict, List, Optional
from pathlib import Path
import logging

logger = logging.getLogger(__name__)


class AlisaPersona:
    """AIã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼ ã‚¢ãƒªã‚µã®ãƒšãƒ«ã‚½ãƒŠã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, persona_data_path: Optional[str] = None):
        """
        ãƒšãƒ«ã‚½ãƒŠãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–
        
        Args:
            persona_data_path: ãƒšãƒ«ã‚½ãƒŠãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        self.persona_data_path = persona_data_path or "data/alisa_persona.json"
        self.writing_samples = []
        self.style_guidelines = self._load_default_guidelines()
        self.vocabulary_preferences = self._load_default_vocabulary()
        
        # æ—¢å­˜ã®ãƒšãƒ«ã‚½ãƒŠãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        self._load_persona_data()
    
    def _load_default_guidelines(self) -> Dict[str, str]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æ–‡ä½“ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’å®šç¾©"""
        return {
            "tone": "è¦ªã—ã¿ã‚„ã™ãã€å°‚é–€ç”¨èªã¯é©å®œåˆ†ã‹ã‚Šã‚„ã™ãè§£èª¬ã™ã‚‹",
            "approach": "èª­è€…ã®ç–‘å•ã«å…ˆå›ã‚Šã—ã¦ç­”ãˆã‚‹ã‚ˆã†ãªã€ä¸å¯§ã§å…·ä½“çš„ãªè§£èª¬",
            "emotion": "ãƒã‚¸ãƒ†ã‚£ãƒ–ã§ã€Sunoã‚’ä½¿ã£ãŸä½œæ›²ã¸ã®èˆˆå‘³ã¨å‰µä½œæ„æ¬²ã‚’å¼·ãå–šèµ·ã™ã‚‹ãƒˆãƒ¼ãƒ³",
            "content_style": "å…·ä½“çš„ãªæ“ä½œæ‰‹é †ã€Sunoã®åˆ©ç”¨äº‹ä¾‹ã€æ´»ç”¨ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è±Šå¯Œã«ç››ã‚Šè¾¼ã‚€",
            "formatting": "ç®‡æ¡æ›¸ãã€å¤ªå­—ã€å¼•ç”¨ãƒ–ãƒ­ãƒƒã‚¯ãªã©ã‚’åŠ¹æœçš„ã«ä½¿ç”¨ã—ã€èª­ã¿ã‚„ã™ã•ã¨è¦–è¦šçš„ãªé­…åŠ›ã‚’é«˜ã‚ã‚‹",
            "interaction": "èª­è€…ã«èªã‚Šã‹ã‘ã‚‹ã‚ˆã†ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªè¡¨ç¾ã‚‚é©å®œç”¨ã„ã‚‹"
        }
    
    def _load_default_vocabulary(self) -> Dict[str, List[str]]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®èªå½™ãƒ»è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®šç¾©"""
        return {
            "greetings": [
                "ã“ã‚“ã«ã¡ã¯ï¼AIã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼ ã‚¢ãƒªã‚µã§ã™ã€‚",
                "éŸ³æ¥½åˆ¶ä½œã®æ–°ã—ã„æ‰‰ã‚’é–‹ãæ™‚ãŒæ¥ã¾ã—ãŸã€‚",
                "Sunoã¨ä¸€ç·’ã«ã€ç´ æ™´ã‚‰ã—ã„éŸ³æ¥½ã®æ—…ã«å‡ºã‹ã‘ã¾ã—ã‚‡ã†ï¼"
            ],
            "encouragements": [
                "å¤§ä¸ˆå¤«ã€ãã£ã¨ã§ãã¾ã™ï¼",
                "ä¸€ç·’ã«æŒ‘æˆ¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚",
                "SunoãŒã‚ãªãŸã®å‰µé€ æ€§ã‚’è§£æ”¾ã—ã¾ã™ã€‚",
                "éŸ³æ¥½åˆ¶ä½œã®æ¥½ã—ã•ã‚’ä½“é¨“ã—ã¦ãã ã•ã„ã€‚"
            ],
            "transitions": [
                "ãã‚Œã§ã¯ã€",
                "æ¬¡ã«ã€",
                "ã“ã“ã§é‡è¦ãªã®ã¯ã€",
                "å®Ÿã¯ã€",
                "ã•ã‚‰ã«èˆˆå‘³æ·±ã„ã“ã¨ã«ã€"
            ],
            "emphasis_patterns": [
                "**{}**",  # å¤ªå­—å¼·èª¿
                "ã€Œ{}ã€",  # éµæ‹¬å¼§å¼·èª¿
                "âœ¨ {} âœ¨",  # è£…é£¾çš„å¼·èª¿
            ],
            "suno_specific": [
                "Sunoã®é­”æ³•",
                "AIä½œæ›²ã®æ–°æ™‚ä»£",
                "éŸ³æ¥½å‰µä½œã®æ°‘ä¸»åŒ–",
                "ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãªå¯èƒ½æ€§",
                "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®åŠ›",
                "AIãƒ¡ãƒ­ãƒ‡ã‚£å·¥æˆ¿"
            ]
        }
    
    def _load_persona_data(self):
        """ä¿å­˜ã•ã‚ŒãŸãƒšãƒ«ã‚½ãƒŠãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        if os.path.exists(self.persona_data_path):
            try:
                with open(self.persona_data_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.writing_samples = data.get('writing_samples', [])
                    self.style_guidelines.update(data.get('style_guidelines', {}))
                    self.vocabulary_preferences.update(data.get('vocabulary_preferences', {}))
                logger.info("ãƒšãƒ«ã‚½ãƒŠãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            except Exception as e:
                logger.error(f"ãƒšãƒ«ã‚½ãƒŠãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def save_persona_data(self):
        """ãƒšãƒ«ã‚½ãƒŠãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        try:
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
            os.makedirs(os.path.dirname(self.persona_data_path), exist_ok=True)
            
            data = {
                'writing_samples': self.writing_samples,
                'style_guidelines': self.style_guidelines,
                'vocabulary_preferences': self.vocabulary_preferences
            }
            
            with open(self.persona_data_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info("ãƒšãƒ«ã‚½ãƒŠãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
        except Exception as e:
            logger.error(f"ãƒšãƒ«ã‚½ãƒŠãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def add_writing_sample(self, sample_text: str, metadata: Optional[Dict] = None):
        """åŸ·ç­†ã‚µãƒ³ãƒ—ãƒ«ã‚’è¿½åŠ """
        sample = {
            'text': sample_text,
            'metadata': metadata or {}
        }
        self.writing_samples.append(sample)
        self.save_persona_data()
    
    def get_style_prompt(self) -> str:
        """AIãƒ¢ãƒ‡ãƒ«ç”¨ã®ã‚¹ã‚¿ã‚¤ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ"""
        prompt_parts = [
            "ã‚ãªãŸã¯ã€ŒAIã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼ ã‚¢ãƒªã‚µã€ã¨ã—ã¦è¨˜äº‹ã‚’åŸ·ç­†ã—ã¦ãã ã•ã„ã€‚",
            "",
            "æ–‡ä½“ã®ç‰¹å¾´ï¼š"
        ]
        
        for key, value in self.style_guidelines.items():
            prompt_parts.append(f"- {value}")
        
        prompt_parts.extend([
            "",
            "ã‚ˆãä½¿ã†è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼š"
        ])
        
        # æŒ¨æ‹¶è¡¨ç¾
        if self.vocabulary_preferences.get('greetings'):
            prompt_parts.append(f"æŒ¨æ‹¶: {', '.join(self.vocabulary_preferences['greetings'][:3])}")
        
        # åŠ±ã¾ã—è¡¨ç¾
        if self.vocabulary_preferences.get('encouragements'):
            prompt_parts.append(f"åŠ±ã¾ã—: {', '.join(self.vocabulary_preferences['encouragements'][:3])}")
        
        # Sunoç‰¹æœ‰ã®è¡¨ç¾
        if self.vocabulary_preferences.get('suno_specific'):
            prompt_parts.append(f"Sunoé–¢é€£: {', '.join(self.vocabulary_preferences['suno_specific'][:3])}")
        
        # åŸ·ç­†ã‚µãƒ³ãƒ—ãƒ«ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
        if self.writing_samples:
            prompt_parts.extend([
                "",
                "éå»ã®åŸ·ç­†ä¾‹ã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š"
            ])
            # æœ€æ–°ã®3ã¤ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ä½¿ç”¨
            for sample in self.writing_samples[-3:]:
                excerpt = sample['text'][:200] + "..." if len(sample['text']) > 200 else sample['text']
                prompt_parts.append(f"- {excerpt}")
        
        return "\n".join(prompt_parts)
    
    def apply_persona_style(self, text: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã«ã‚¢ãƒªã‚µã®ãƒšãƒ«ã‚½ãƒŠã‚¹ã‚¿ã‚¤ãƒ«ã‚’é©ç”¨"""
        styled_text = text
        
        # å€‹äººçš„ãªä½“é¨“è«‡ã‚’è¿½åŠ ã™ã‚‹ä¾‹
        if "Sunoã‚’ä½¿ã£ã¦" in text and "ç§ã‚‚" not in text:
            personal_experiences = [
                "å®Ÿã¯ç§ã‚‚æœ€åˆã¯åŠä¿¡åŠç–‘ã§ã—ãŸã€‚",
                "ç§ã‚‚å®Ÿéš›ã«è©¦ã—ã¦ã¿ã¦é©šãã¾ã—ãŸã€‚",
                "ç§ã®çµŒé¨“ã§ã¯ã€"
            ]
            # ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã—ã¦æŒ¿å…¥ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯é©åˆ‡ãªä½ç½®ã«ï¼‰
            # ã“ã“ã§ã¯ç°¡ç•¥åŒ–
        
        # èª­è€…ã¸ã®èªã‚Šã‹ã‘ã‚’è¿½åŠ 
        if "ã§ãã¾ã™ã€‚" in styled_text:
            styled_text = styled_text.replace(
                "ã§ãã¾ã™ã€‚",
                "ã§ãã¾ã™ã€‚ãã£ã¨ã‚ãªãŸã«ã‚‚ç´ æ™´ã‚‰ã—ã„éŸ³æ¥½ãŒä½œã‚Œã‚‹ã¯ãšã§ã™ã€‚"
            )
        
        return styled_text
    
    def get_cta_template(self) -> str:
        """CTAï¼ˆCall to Actionï¼‰ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—"""
        return """---
<div style="text-align: center; padding: 20px 25px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 12px; margin: 25px auto; max-width: 600px; box-shadow: 0 8px 25px rgba(0,0,0,0.15);">

<h3 style="color: white; margin: 0 0 12px 0; font-size: 22px; font-weight: bold; text-shadow: 0 2px 4px rgba(0,0,0,0.2);">
âœ¨ AI Melody Kobo ç„¡æ–™ãƒ¡ãƒ«ãƒã‚¬ âœ¨
</h3>

<p style="color: white; font-size: 15px; margin-bottom: 10px; line-height: 1.5; font-weight: 500;">
AIéŸ³æ¥½ã®æœ€æ–°æƒ…å ±ã¨ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’é…ä¿¡ä¸­ï¼
</p>

<p style="color: #ffeb3b; font-size: 16px; margin-bottom: 20px; font-weight: bold; text-shadow: 0 1px 3px rgba(0,0,0,0.3);">
ğŸ ç™»éŒ²ç‰¹å…¸ï¼šAIéŸ³æ¥½ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ100é¸ã‚’ç„¡æ–™é…å¸ƒ
</p>

<div style="display: inline-block;">
<a href="#newsletter-signup" 
   onmouseover="this.style.background='linear-gradient(45deg, #ff5252, #ff1744)'; this.style.transform='translateY(-2px)'; this.style.boxShadow='0 5px 20px rgba(238,90,111,0.4)';" 
   onmouseout="this.style.background='linear-gradient(45deg, #ff6b6b, #ee5a6f)'; this.style.transform='translateY(0)'; this.style.boxShadow='0 3px 15px rgba(238,90,111,0.3)';" 
   style="display: block; background: linear-gradient(45deg, #ff6b6b, #ee5a6f); color: white; padding: 13px 45px 12px 45px; text-decoration: none; border-radius: 30px; font-weight: bold; font-size: 16px; box-shadow: 0 3px 15px rgba(238,90,111,0.3); transition: all 0.3s ease; text-shadow: 0 1px 2px rgba(0,0,0,0.2); line-height: 1; position: relative;">
ğŸš€ ç„¡æ–™ç™»éŒ²
</a>
</div>

</div>
---"""
    
    def get_article_structure_template(self) -> Dict[str, str]:
        """è¨˜äº‹æ§‹é€ ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—"""
        return {
            "introduction": "èª­è€…ã®å…±æ„Ÿã‚’å‘¼ã³ã€Sunoã®é­…åŠ›ã‚’ä¼ãˆã‚‹å°å…¥",
            "toc": "è«–ç†çš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„ç›®æ¬¡æ§‹æˆï¼ˆH2ã€H3ï¼‰",
            "main_content": "å…·ä½“ä¾‹ã¨ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰",
            "cta_mid": "è¨˜äº‹ä¸­ç›¤ã§ã®CTAæŒ¿å…¥",
            "conclusion": "ãƒã‚¸ãƒ†ã‚£ãƒ–ã§è¡Œå‹•ã‚’ä¿ƒã™ã¾ã¨ã‚",
            "cta_end": "è¨˜äº‹æœ«å°¾ã§ã®CTAæŒ¿å…¥",
            "tags": "Sunoé–¢é€£ã®WordPressã‚¿ã‚°",
            "meta": "SEOæœ€é©åŒ–ã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³"
        }
    
    def analyze_writing_style(self, text: str) -> Dict[str, any]:
        """ãƒ†ã‚­ã‚¹ãƒˆã®æ–‡ä½“ã‚’åˆ†æ"""
        analysis = {
            "sentence_count": len(text.split('ã€‚')),
            "exclamation_count": text.count('ï¼'),
            "question_count": text.count('ï¼Ÿ'),
            "emoji_count": sum(1 for char in text if ord(char) > 0x1F300),
            "suno_mentions": text.lower().count('suno'),
            "personal_pronouns": sum(text.count(pronoun) for pronoun in ['ç§', 'ã‚ãªãŸ', 'çš†ã•ã‚“']),
            "encouragement_phrases": sum(1 for phrase in self.vocabulary_preferences['encouragements'] if phrase in text)
        }
        
        return analysis