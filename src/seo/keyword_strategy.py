"""
SEO Keyword Strategy System
AI Melody Kobo - SEOæœ€é©åŒ–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æˆ¦ç•¥ã‚·ã‚¹ãƒ†ãƒ 
"""

import json
import logging
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from pathlib import Path
import random
import re

logger = logging.getLogger(__name__)


class SEOKeywordStrategy:
    """SEOæˆ¦ç•¥ã«åŸºã¥ãã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, strategy_file: str = None):
        """
        åˆæœŸåŒ–
        
        Args:
            strategy_file: SEOæˆ¦ç•¥ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        self.strategy_file = Path(strategy_file or "data/seo_strategy.json")
        self.strategy_file.parent.mkdir(parents=True, exist_ok=True)
        
        # SEOæˆ¦ç•¥ãƒ‡ãƒ¼ã‚¿
        self.seo_data = self._load_strategy_data()
        
        # æœˆåˆ¥æ¤œç´¢ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆä»®æƒ³ãƒ‡ãƒ¼ã‚¿ï¼‰
        self.seasonal_trends = self._get_seasonal_trends()
    
    def _load_strategy_data(self) -> Dict:
        """SEOæˆ¦ç•¥ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        if self.strategy_file.exists():
            try:
                with open(self.strategy_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"SEOæˆ¦ç•¥ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®SEOæˆ¦ç•¥ãƒ‡ãƒ¼ã‚¿
        return {
            "primary_keywords": {
                # é«˜æ¤œç´¢ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒ»ä½ç«¶åˆã‚’ç‹™ã†
                "suno": {
                    "main": ["Suno", "Suno AI", "ã‚¹ãƒ¼ãƒ"],
                    "search_volume": 50000,
                    "competition": "medium",
                    "variations": [
                        "Suno ä½¿ã„æ–¹", "Suno AI éŸ³æ¥½ç”Ÿæˆ", "Suno ã¨ã¯",
                        "Suno æ–™é‡‘", "Suno å•†ç”¨åˆ©ç”¨", "Suno ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
                        "Suno ç„¡æ–™", "Suno ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", "Suno æ—¥æœ¬èª"
                    ]
                },
                "ai_music": {
                    "main": ["AIéŸ³æ¥½", "AIä½œæ›²", "AIãƒŸãƒ¥ãƒ¼ã‚¸ãƒƒã‚¯"],
                    "search_volume": 30000,
                    "competition": "high",
                    "variations": [
                        "AIéŸ³æ¥½ ä½œã‚Šæ–¹", "AIä½œæ›² ç„¡æ–™", "AIéŸ³æ¥½ç”Ÿæˆ",
                        "AIéŸ³æ¥½ ãƒ„ãƒ¼ãƒ«", "AIä½œæ›² ã‚¢ãƒ—ãƒª", "AIéŸ³æ¥½ è‘—ä½œæ¨©"
                    ]
                },
                "voice_synthesis": {
                    "main": ["AIéŸ³å£°åˆæˆ", "éŸ³å£°åˆæˆ", "TTS"],
                    "search_volume": 20000,
                    "competition": "medium",
                    "variations": [
                        "AIéŸ³å£°åˆæˆ ç„¡æ–™", "éŸ³å£°åˆæˆ ã‚½ãƒ•ãƒˆ", "TTS ã‚¨ãƒ³ã‚¸ãƒ³",
                        "éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³", "AIå£°å„ª", "ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’"
                    ]
                }
            },
            
            "long_tail_keywords": {
                # ãƒ­ãƒ³ã‚°ãƒ†ãƒ¼ãƒ«ã§ç¢ºå®Ÿã«ãƒ©ãƒ³ã‚¯ã‚¤ãƒ³ã‚’ç‹™ã†
                "tutorial": [
                    "Suno AI ä½¿ã„æ–¹ åˆå¿ƒè€…",
                    "AIéŸ³æ¥½ ä½œã‚Šæ–¹ ç„¡æ–™ ã‚¢ãƒ—ãƒª",
                    "éŸ³å£°åˆæˆ Python å®Ÿè£…æ–¹æ³•",
                    "AIä½œæ›² ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ æ›¸ãæ–¹",
                    "Suno ãƒ—ãƒ­ç‰ˆ æ–™é‡‘ æ¯”è¼ƒ"
                ],
                "comparison": [
                    "Suno vs Udio æ¯”è¼ƒ",
                    "AIéŸ³æ¥½ãƒ„ãƒ¼ãƒ« ãŠã™ã™ã‚ 2024",
                    "éŸ³å£°åˆæˆã‚½ãƒ•ãƒˆ æ¯”è¼ƒ ç„¡æ–™",
                    "AIä½œæ›²ã‚¢ãƒ—ãƒª ãƒ©ãƒ³ã‚­ãƒ³ã‚°",
                    "MusicGen Suno é•ã„"
                ],
                "technical": [
                    "AIéŸ³æ¥½ API é–‹ç™º",
                    "éŸ³å£°åˆæˆ ãƒ¢ãƒ‡ãƒ« å­¦ç¿’",
                    "Suno API ä½¿ã„æ–¹",
                    "AIéŸ³æ¥½ è‘—ä½œæ¨© å•†ç”¨åˆ©ç”¨",
                    "éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ æŠ€è¡“ è§£èª¬"
                ]
            },
            
            "semantic_keywords": {
                # é–¢é€£èªãƒ»å…±èµ·èªã§æ–‡è„ˆã‚’å¼·åŒ–
                "music_production": [
                    "éŸ³æ¥½åˆ¶ä½œ", "æ¥½æ›²åˆ¶ä½œ", "ä½œæ›²", "ç·¨æ›²", "ãƒŸãƒƒã‚¯ã‚¹",
                    "ãƒã‚¹ã‚¿ãƒªãƒ³ã‚°", "DAW", "ãƒ—ãƒ­ãƒ‡ãƒ¥ãƒ¼ã‚µãƒ¼", "ãƒ“ãƒ¼ãƒˆåˆ¶ä½œ"
                ],
                "ai_technology": [
                    "äººå·¥çŸ¥èƒ½", "æ©Ÿæ¢°å­¦ç¿’", "ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°", "ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯",
                    "ç”ŸæˆAI", "ChatGPT", "å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«", "Transformer"
                ],
                "audio_tech": [
                    "ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª", "ã‚µã‚¦ãƒ³ãƒ‰", "éŸ³éŸ¿", "ãƒ‡ã‚¸ã‚¿ãƒ«éŸ³æ¥½", "ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°",
                    "éŸ³è³ª", "ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°", "ã‚·ãƒ³ã‚»ã‚µã‚¤ã‚¶ãƒ¼", "ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ"
                ]
            },
            
            "intent_based_keywords": {
                # æ¤œç´¢æ„å›³åˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                "informational": [
                    "ã¨ã¯", "ä»•çµ„ã¿", "åŸç†", "æ­´å²", "ç‰¹å¾´", "ãƒ¡ãƒªãƒƒãƒˆ", "ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ"
                ],
                "navigational": [
                    "å…¬å¼ã‚µã‚¤ãƒˆ", "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", "ãƒ­ã‚°ã‚¤ãƒ³", "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆ"
                ],
                "transactional": [
                    "ç„¡æ–™", "æœ‰æ–™", "æ–™é‡‘", "ä¾¡æ ¼", "è³¼å…¥", "å¥‘ç´„", "ãƒ—ãƒ©ãƒ³"
                ],
                "commercial": [
                    "æ¯”è¼ƒ", "ãŠã™ã™ã‚", "ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "ãƒ¬ãƒ“ãƒ¥ãƒ¼", "è©•ä¾¡", "å£ã‚³ãƒŸ"
                ]
            }
        }
    
    def _get_seasonal_trends(self) -> Dict:
        """å­£ç¯€çš„æ¤œç´¢ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—"""
        return {
            "1": {"boost": ["æ–°å¹´", "ç›®æ¨™", "å§‹ã‚ã‚‹", "2024å¹´"], "factor": 1.3},
            "2": {"boost": ["ãƒãƒ¬ãƒ³ã‚¿ã‚¤ãƒ³", "æ‹æ„›", "ãƒ©ãƒ–ã‚½ãƒ³ã‚°"], "factor": 1.1},
            "3": {"boost": ["å’æ¥­", "æ–°ç”Ÿæ´»", "æ˜¥"], "factor": 1.2},
            "4": {"boost": ["å…¥å­¦", "æ–°å¹´åº¦", "ãƒ•ãƒ¬ãƒƒã‚·ãƒ¥"], "factor": 1.4},
            "5": {"boost": ["GW", "é€£ä¼‘", "è¶£å‘³"], "factor": 1.2},
            "6": {"boost": ["æ¢…é›¨", "ã‚¤ãƒ³ãƒ‰ã‚¢", "éŸ³æ¥½"], "factor": 1.0},
            "7": {"boost": ["å¤ä¼‘ã¿", "å¤", "ãƒ•ã‚§ã‚¹"], "factor": 1.3},
            "8": {"boost": ["ãŠç›†", "ä¼‘æš‡", "åˆ¶ä½œ"], "factor": 1.2},
            "9": {"boost": ["ç§‹", "èŠ¸è¡“", "æ–‡åŒ–"], "factor": 1.1},
            "10": {"boost": ["ãƒãƒ­ã‚¦ã‚£ãƒ³", "ã‚¤ãƒ™ãƒ³ãƒˆ"], "factor": 1.2},
            "11": {"boost": ["ç´…è‘‰", "ç§‹", "è½ã¡ç€ã"], "factor": 1.0},
            "12": {"boost": ["ã‚¯ãƒªã‚¹ãƒã‚¹", "å¹´æœ«", "ã¾ã¨ã‚"], "factor": 1.4}
        }
    
    def generate_seo_optimized_keywords(self, 
                                      article_type: str,
                                      tool_name: str = None,
                                      target_difficulty: str = "medium") -> Dict[str, List[str]]:
        """
        SEOæœ€é©åŒ–ã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆ
        
        Args:
            article_type: è¨˜äº‹ã‚¿ã‚¤ãƒ—
            tool_name: å¯¾è±¡ãƒ„ãƒ¼ãƒ«å
            target_difficulty: é›£æ˜“åº¦ (easy/medium/hard)
            
        Returns:
            ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚»ãƒƒãƒˆ
        """
        current_month = str(datetime.now().month)
        seasonal_boost = self.seasonal_trends.get(current_month, {"boost": [], "factor": 1.0})
        
        # ãƒ—ãƒ©ã‚¤ãƒãƒªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é¸æŠ
        primary_keywords = []
        if tool_name and tool_name.lower() in self.seo_data["primary_keywords"]:
            tool_data = self.seo_data["primary_keywords"][tool_name.lower()]
            primary_keywords.extend(tool_data["main"])
            # æ¤œç´¢ãƒœãƒªãƒ¥ãƒ¼ãƒ ãŒé«˜ã„é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ 
            primary_keywords.extend(random.sample(tool_data["variations"], 3))
        
        # è¨˜äº‹ã‚¿ã‚¤ãƒ—åˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        type_keywords = []
        if article_type in ["tutorial", "beginner_guide"]:
            type_keywords.extend(random.sample(self.seo_data["long_tail_keywords"]["tutorial"], 2))
        elif article_type in ["tool_comparison", "tool_review"]:
            type_keywords.extend(random.sample(self.seo_data["long_tail_keywords"]["comparison"], 2))
        elif article_type in ["programming", "app_development"]:
            type_keywords.extend(random.sample(self.seo_data["long_tail_keywords"]["technical"], 2))
        
        # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        semantic_keywords = []
        semantic_keywords.extend(random.sample(self.seo_data["semantic_keywords"]["music_production"], 2))
        semantic_keywords.extend(random.sample(self.seo_data["semantic_keywords"]["ai_technology"], 2))
        
        # æ¤œç´¢æ„å›³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        intent_keywords = []
        if article_type in ["beginner_guide", "tutorial"]:
            intent_keywords.extend(random.sample(self.seo_data["intent_based_keywords"]["informational"], 2))
        elif article_type == "tool_comparison":
            intent_keywords.extend(random.sample(self.seo_data["intent_based_keywords"]["commercial"], 2))
        
        # å­£ç¯€çš„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        seasonal_keywords = random.sample(seasonal_boost["boost"], min(2, len(seasonal_boost["boost"])))
        
        return {
            "primary": primary_keywords,
            "long_tail": type_keywords,
            "semantic": semantic_keywords,
            "intent": intent_keywords,
            "seasonal": seasonal_keywords,
            "search_volume_estimate": self._estimate_search_volume(primary_keywords),
            "competition_level": target_difficulty
        }
    
    def _estimate_search_volume(self, keywords: List[str]) -> int:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ¤œç´¢ãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚’æ¨å®š"""
        total_volume = 0
        for keyword in keywords:
            for tool, data in self.seo_data["primary_keywords"].items():
                if keyword.lower() in [k.lower() for k in data["main"]]:
                    total_volume += data["search_volume"]
                    break
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                total_volume += 1000
        return total_volume
    
    def generate_seo_title_variations(self, 
                                    base_topic: str,
                                    keywords: Dict[str, List[str]],
                                    max_length: int = 60) -> List[str]:
        """
        SEOæœ€é©åŒ–ã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ
        
        Args:
            base_topic: ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ãƒˆãƒ”ãƒƒã‚¯
            keywords: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚»ãƒƒãƒˆ
            max_length: æœ€å¤§æ–‡å­—æ•°
            
        Returns:
            ã‚¿ã‚¤ãƒˆãƒ«ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
        """
        current_year = datetime.now().year
        current_month = datetime.now().month
        
        # ã‚¿ã‚¤ãƒˆãƒ«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        templates = [
            "ã€{year}å¹´æœ€æ–°ã€‘{primary} {topic}",
            "{primary}ã§{topic}ã™ã‚‹æ–¹æ³•ã€å®Œå…¨ã‚¬ã‚¤ãƒ‰ã€‘",
            "ã€ä¿å­˜ç‰ˆã€‘{primary} {topic} - {benefit}",
            "{primary} {topic}ã®å§‹ã‚æ–¹ï½œ{month}æœˆç‰ˆ",
            "ã€å®Ÿè·µã€‘{primary}ã‚’ä½¿ã£ãŸ{topic}ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯",
            "{primary} {topic}å…¥é–€ - åˆå¿ƒè€…å‘ã‘å®Œå…¨è§£èª¬",
            "ãƒ—ãƒ­ãŒæ•™ãˆã‚‹{primary} {topic}ã®æ¥µæ„",
            "{comparison}ï¼Ÿ{primary} {topic}ã‚’å¾¹åº•æ¯”è¼ƒ"
        ]
        
        variations = []
        
        for template in templates:
            try:
                title = template.format(
                    year=current_year,
                    month=current_month,
                    primary=random.choice(keywords.get("primary", ["AIéŸ³æ¥½"])),
                    topic=base_topic,
                    benefit=random.choice(["åˆå¿ƒè€…ã§ã‚‚ç°¡å˜", "ãƒ—ãƒ­ç´šã®ã‚¯ã‚ªãƒªãƒ†ã‚£", "ç„¡æ–™ã§å§‹ã‚ã‚‰ã‚Œã‚‹"]),
                    comparison=random.choice(["ã©ã£ã¡ãŒã„ã„", "ä½•ãŒé•ã†", "æ¯”è¼ƒæ¤œè¨¼"])
                )
                
                if len(title) <= max_length:
                    variations.append(title)
            except (KeyError, IndexError):
                continue
        
        return variations[:5]  # ä¸Šä½5ã¤ã‚’è¿”ã™
    
    def optimize_content_structure(self, content: str, keywords: Dict[str, List[str]]) -> str:
        """
        ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’SEOæœ€é©åŒ–
        
        Args:
            content: å…ƒã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
            keywords: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚»ãƒƒãƒˆ
            
        Returns:
            æœ€é©åŒ–ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        """
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¯†åº¦ã®æœ€é©åŒ–ï¼ˆè‡ªç„¶ãªå½¢ã§ï¼‰
        optimized_content = content
        
        # ãƒ—ãƒ©ã‚¤ãƒãƒªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’é©åˆ‡ãªä½ç½®ã«é…ç½®
        primary_keywords = keywords.get("primary", [])
        if primary_keywords:
            main_keyword = primary_keywords[0]
            
            # è¦‹å‡ºã—ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚ã‚‹
            optimized_content = self._optimize_headings(optimized_content, main_keyword)
            
            # å°å…¥éƒ¨åˆ†ã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¨€åŠ
            optimized_content = self._optimize_introduction(optimized_content, main_keyword)
            
            # ã¾ã¨ã‚éƒ¨åˆ†ã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å†åº¦ä½¿ç”¨
            optimized_content = self._optimize_conclusion(optimized_content, main_keyword)
        
        # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è‡ªç„¶ã«é…ç½®
        semantic_keywords = keywords.get("semantic", [])
        optimized_content = self._add_semantic_keywords(optimized_content, semantic_keywords)
        
        return optimized_content
    
    def _optimize_headings(self, content: str, keyword: str) -> str:
        """è¦‹å‡ºã—ã‚’æœ€é©åŒ–"""
        lines = content.split('\n')
        optimized_lines = []
        
        for line in lines:
            if line.startswith('## ') and keyword.lower() not in line.lower():
                # H2è¦‹å‡ºã—ã®æœ€åˆã®ã‚‚ã®ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚ã‚‹
                if len([l for l in optimized_lines if l.startswith('## ')]) == 0:
                    heading_text = line[3:].strip()
                    line = f"## {keyword}ã§{heading_text}"
            optimized_lines.append(line)
        
        return '\n'.join(optimized_lines)
    
    def _optimize_introduction(self, content: str, keyword: str) -> str:
        """å°å…¥éƒ¨åˆ†ã‚’æœ€é©åŒ–"""
        lines = content.split('\n')
        
        # æœ€åˆã®æ®µè½ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        first_paragraph_end = 0
        for i, line in enumerate(lines):
            if line.strip() == '' and i > 5:  # ç©ºè¡Œã§æ®µè½åŒºåˆ‡ã‚Š
                first_paragraph_end = i
                break
        
        first_paragraph = '\n'.join(lines[:first_paragraph_end])
        if keyword.lower() not in first_paragraph.lower():
            # æœ€åˆã®æ–‡ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚ã‚‹
            if lines and not lines[0].startswith('#'):
                lines[0] = f"{keyword}ã«ã¤ã„ã¦è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚" + lines[0]
        
        return '\n'.join(lines)
    
    def _optimize_conclusion(self, content: str, keyword: str) -> str:
        """ã¾ã¨ã‚éƒ¨åˆ†ã‚’æœ€é©åŒ–"""
        lines = content.split('\n')
        
        # ã¾ã¨ã‚ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã™
        summary_index = -1
        for i, line in enumerate(lines):
            if any(word in line.lower() for word in ['ã¾ã¨ã‚', 'conclusion', 'æœ€å¾Œã«']):
                summary_index = i
                break
        
        if summary_index > 0 and keyword.lower() not in lines[summary_index:]:
            # ã¾ã¨ã‚éƒ¨åˆ†ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ 
            for i in range(summary_index + 1, len(lines)):
                if lines[i].strip() and not lines[i].startswith('#'):
                    lines[i] = f"{keyword}ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€" + lines[i]
                    break
        
        return '\n'.join(lines)
    
    def _add_semantic_keywords(self, content: str, semantic_keywords: List[str]) -> str:
        """ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ """
        # è‡ªç„¶ãªå½¢ã§ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’é…ç½®
        # å®Ÿè£…ã¯ç°¡ç•¥åŒ–ï¼ˆå®Ÿéš›ã«ã¯ã‚ˆã‚Šé«˜åº¦ãªè‡ªç„¶è¨€èªå‡¦ç†ãŒå¿…è¦ï¼‰
        return content
    
    def generate_meta_description(self, title: str, keywords: Dict[str, List[str]]) -> str:
        """SEOæœ€é©åŒ–ã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆãŒç©ºã§ãªã„ã“ã¨ã‚’ç¢ºèª
        primary_keywords = keywords.get("primary", ["AIéŸ³æ¥½"])
        if not primary_keywords:
            primary_keywords = ["AIéŸ³æ¥½"]
        primary_keyword = primary_keywords[0]
        intent_keywords = keywords.get("intent", [])
        
        templates = [
            f"{primary_keyword}ã®ä½¿ã„æ–¹ã‚’è©³ã—ãè§£èª¬ã€‚åˆå¿ƒè€…ã§ã‚‚ç°¡å˜ã«å§‹ã‚ã‚‰ã‚Œã‚‹æ–¹æ³•ã‚’ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã§ç´¹ä»‹ã—ã¾ã™ã€‚",
            f"ã€æœ€æ–°ç‰ˆã€‘{primary_keyword}ã®ç‰¹å¾´ãƒ»æ–™é‡‘ãƒ»ä½¿ã„æ–¹ã‚’å¾¹åº•è§£èª¬ã€‚ä»–ãƒ„ãƒ¼ãƒ«ã¨ã®æ¯”è¼ƒã‚‚å«ã‚ã¦å®Œå…¨ã‚¬ã‚¤ãƒ‰ã€‚",
            f"{primary_keyword}ã§é«˜å“è³ªãªéŸ³æ¥½ã‚’ä½œã‚‹æ–¹æ³•ã‚’è§£èª¬ã€‚ãƒ—ãƒ­ãŒæ•™ãˆã‚‹ã‚³ãƒ„ã¨ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’ãŠä¼ãˆã—ã¾ã™ã€‚",
            f"{primary_keyword}ã«ã¤ã„ã¦çŸ¥ã‚ŠãŸã„æ–¹å¿…è¦‹ï¼åŸºæœ¬ã‹ã‚‰å¿œç”¨ã¾ã§åˆ†ã‹ã‚Šã‚„ã™ãè§£èª¬ã—ãŸå®Œå…¨ã‚¬ã‚¤ãƒ‰ã§ã™ã€‚"
        ]
        
        meta_desc = random.choice(templates)
        
        # 120æ–‡å­—ä»¥å†…ã«èª¿æ•´
        if len(meta_desc) > 120:
            meta_desc = meta_desc[:117] + "..."
        
        return meta_desc
    
    def get_keyword_suggestions(self, base_keyword: str) -> List[str]:
        """é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ææ¡ˆ"""
        suggestions = []
        
        # æ—¢å­˜ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é–¢é€£èªã‚’æŠ½å‡º
        for category, keywords in self.seo_data["long_tail_keywords"].items():
            for keyword in keywords:
                if base_keyword.lower() in keyword.lower():
                    suggestions.append(keyword)
        
        # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰ã‚‚ææ¡ˆ
        for category, keywords in self.seo_data["semantic_keywords"].items():
            suggestions.extend(random.sample(keywords, min(2, len(keywords))))
        
        return suggestions[:10]


def main():
    """ãƒ†ã‚¹ãƒˆç”¨ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    seo_strategy = SEOKeywordStrategy()
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆãƒ†ã‚¹ãƒˆ
    keywords = seo_strategy.generate_seo_optimized_keywords(
        article_type="tutorial",
        tool_name="Suno",
        target_difficulty="medium"
    )
    
    print("ğŸ¯ ç”Ÿæˆã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚»ãƒƒãƒˆ:")
    for category, kw_list in keywords.items():
        print(f"  {category}: {kw_list}")
    
    # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆãƒ†ã‚¹ãƒˆ
    titles = seo_strategy.generate_seo_title_variations(
        "éŸ³æ¥½åˆ¶ä½œã®å§‹ã‚æ–¹",
        keywords
    )
    
    print(f"\nğŸ“ SEOæœ€é©åŒ–ã‚¿ã‚¤ãƒˆãƒ«æ¡ˆ:")
    for i, title in enumerate(titles, 1):
        print(f"  {i}. {title}")
    
    # ãƒ¡ã‚¿ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆãƒ†ã‚¹ãƒˆ
    meta_desc = seo_strategy.generate_meta_description(titles[0], keywords)
    print(f"\nğŸ“‹ ãƒ¡ã‚¿ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³:")
    print(f"  {meta_desc}")


if __name__ == "__main__":
    main()